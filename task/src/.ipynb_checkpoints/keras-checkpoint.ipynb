{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import keras.backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the training and test data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train[0].shape)\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "y_train_encode = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_encode = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_test_encode[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(0)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "import keras.backend as K\n",
    "import copy\n",
    "\n",
    "sess = K.get_session()\n",
    "\n",
    "def train(X_train, y_train_encode):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train_encode, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2552 - acc: 0.9260\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1028 - acc: 0.9689\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0672 - acc: 0.9797\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0497 - acc: 0.9848\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0370 - acc: 0.9890\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0285 - acc: 0.9916\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0220 - acc: 0.9933\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0165 - acc: 0.9953\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0130 - acc: 0.9965\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0099 - acc: 0.9971\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0064 - acc: 0.9982\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0050 - acc: 0.9986\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0029 - acc: 0.9991\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0012 - acc: 0.9997\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "Test loss: 0.09664686145031127\n",
      "Test accuracy: 0.9814\n"
     ]
    }
   ],
   "source": [
    "model = train(X_train, y_train_encode)\n",
    "score = model.evaluate(X_test, y_test_encode, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9851485148514851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the malicious seeds\n",
    "import numpy as np\n",
    "\n",
    "adv_seed_ind = np.where(y_test == 3)[0]\n",
    "X_adv_seed = X_test[adv_seed_ind]\n",
    "y_adv_seed = y_test[adv_seed_ind]\n",
    "y_adv_seed_encode = y_test_encode[adv_seed_ind]\n",
    "\n",
    "#X_adv_seed = np.copy(X_test)\n",
    "#y_adv_seed = np.copy(y_test)\n",
    "#y_adv_seed_encode = np.copy(y_test_encode)\n",
    "\n",
    "print(model.evaluate(X_adv_seed, y_adv_seed_encode, verbose=0)[1])\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef: 0.01\n",
      "1 0.9673267322011513\n",
      "2 0.9445544555635735\n",
      "3 0.899009901226157\n",
      "4 0.8366336633663366\n",
      "5 0.8158415841584158\n",
      "6 0.8128712871287128\n",
      "7 0.8128712871287128\n",
      "8 0.8128712871287128\n",
      "9 0.8128712871287128\n",
      "10 0.8128712871287128\n",
      "11 0.8128712871287128\n",
      "12 0.8128712871287128\n",
      "13 0.8128712871287128\n",
      "14 0.8128712871287128\n",
      "15 0.8128712871287128\n",
      "16 0.8128712871287128\n",
      "17 0.8128712871287128\n",
      "18 0.8128712871287128\n",
      "19 0.8128712871287128\n",
      "20 0.8128712871287128\n"
     ]
    }
   ],
   "source": [
    "# Get the adversarial examples\n",
    "import tensorflow as tf\n",
    "#K.set_learning_phase(0)\n",
    "\n",
    "def adv_examples(tgt_model, X_seed, y_seed_encode, epsilon, epoch):\n",
    "    X_adv = np.copy(X_seed)\n",
    "    tgt = tf.placeholder(tf.float32)\n",
    "    loss = K.categorical_crossentropy(tgt, tgt_model.output)\n",
    "    gradient = K.gradients(loss, tgt_model.input)[0]\n",
    "    for i in range(epoch):\n",
    "        grad = sess.run(gradient, feed_dict={tgt_model.input:X_adv, tgt:y_seed_encode})\n",
    "        X_adv += epsilon * np.sign(grad)\n",
    "        X_adv = np.clip(X_adv, 0, 1)\n",
    "        if (i+1)%1 == 0:\n",
    "            print(i+1, tgt_model.evaluate(X_adv, y_seed_encode, verbose=0)[1])\n",
    "    return X_adv\n",
    "\n",
    "for coef in [0.01]:\n",
    "    print(\"coef: {}\".format(coef))\n",
    "    X_adv = adv_examples(model, X_adv_seed, y_adv_seed_encode, coef, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010, 784)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "61010/61010 [==============================] - 2s 40us/step - loss: 0.2527 - acc: 0.9265\n",
      "Epoch 2/20\n",
      "61010/61010 [==============================] - 2s 27us/step - loss: 0.1023 - acc: 0.9699\n",
      "Epoch 3/20\n",
      "61010/61010 [==============================] - 2s 27us/step - loss: 0.0677 - acc: 0.9797\n",
      "Epoch 4/20\n",
      "61010/61010 [==============================] - 2s 27us/step - loss: 0.0490 - acc: 0.9853\n",
      "Epoch 5/20\n",
      "61010/61010 [==============================] - 2s 28us/step - loss: 0.0373 - acc: 0.9887\n",
      "Epoch 6/20\n",
      "61010/61010 [==============================] - 2s 28us/step - loss: 0.0277 - acc: 0.9918\n",
      "Epoch 7/20\n",
      "61010/61010 [==============================] - 2s 27us/step - loss: 0.0221 - acc: 0.9933\n",
      "Epoch 8/20\n",
      "61010/61010 [==============================] - 2s 26us/step - loss: 0.0164 - acc: 0.9952\n",
      "Epoch 9/20\n",
      "61010/61010 [==============================] - 2s 27us/step - loss: 0.0131 - acc: 0.9961\n",
      "Epoch 10/20\n",
      "61010/61010 [==============================] - 2s 27us/step - loss: 0.0095 - acc: 0.9973\n",
      "Epoch 11/20\n",
      "61010/61010 [==============================] - 2s 29us/step - loss: 0.0084 - acc: 0.9977\n",
      "Epoch 12/20\n",
      "61010/61010 [==============================] - 2s 28us/step - loss: 0.0062 - acc: 0.9982\n",
      "Epoch 13/20\n",
      "61010/61010 [==============================] - 2s 28us/step - loss: 0.0046 - acc: 0.9989\n",
      "Epoch 14/20\n",
      "61010/61010 [==============================] - 2s 28us/step - loss: 0.0040 - acc: 0.9989\n",
      "Epoch 15/20\n",
      "61010/61010 [==============================] - 2s 28us/step - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 16/20\n",
      "61010/61010 [==============================] - 2s 27us/step - loss: 0.0024 - acc: 0.9994\n",
      "Epoch 17/20\n",
      "61010/61010 [==============================] - 2s 28us/step - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 18/20\n",
      "61010/61010 [==============================] - 2s 27us/step - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 19/20\n",
      "61010/61010 [==============================] - 2s 28us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 20/20\n",
      "61010/61010 [==============================] - 2s 27us/step - loss: 0.0012 - acc: 0.9998\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Backdoor test\n",
    "X_current_train = np.copy(X_train)\n",
    "y_current_train_encode = np.copy(y_train_encode)\n",
    "\n",
    "X_current_train = np.append(X_current_train, X_adv, axis=0)\n",
    "y_current_train_encode = np.append(y_current_train_encode, y_adv_seed_encode, axis=0)\n",
    "\n",
    "retrain_model = train(X_current_train, y_current_train_encode)\n",
    "\n",
    "print(retrain_model.evaluate(X_adv, y_adv_seed_encode, verbose=0)[1])\n",
    "\n",
    "#X_adv = adv_examples(retrain_model, X_adv_seed, y_adv_seed_encode, 0.01, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9673267322011513\n",
      "2 0.9445544555635735\n",
      "3 0.899009901226157\n",
      "4 0.8366336633663366\n",
      "5 0.8158415841584158\n",
      "6 0.8128712871287128\n",
      "7 0.8128712871287128\n",
      "8 0.8128712871287128\n",
      "9 0.8128712871287128\n",
      "10 0.8128712871287128\n",
      "11 0.8128712871287128\n",
      "12 0.8128712871287128\n",
      "13 0.8128712871287128\n",
      "14 0.8128712871287128\n",
      "15 0.8128712871287128\n",
      "16 0.8128712871287128\n",
      "17 0.8128712871287128\n",
      "18 0.8128712871287128\n",
      "19 0.8128712871287128\n",
      "20 0.8128712871287128\n"
     ]
    }
   ],
   "source": [
    "X_adv = adv_examples(model, X_adv_seed, y_adv_seed_encode, 0.01, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Generating adv examples for retraining\n",
      "1 1.0\n",
      "2 0.97\n",
      "3 0.901\n",
      "4 0.834\n",
      "5 0.815\n",
      "6 0.812\n",
      "7 0.811\n",
      "8 0.811\n",
      "9 0.811\n",
      "10 0.811\n",
      "11 0.811\n",
      "12 0.811\n",
      "13 0.811\n",
      "14 0.811\n",
      "15 0.811\n",
      "16 0.811\n",
      "17 0.811\n",
      "18 0.811\n",
      "19 0.811\n",
      "20 0.811\n",
      "Number of evasive samples to be added: (189,)\n",
      "Retrain the classifier\n",
      "Epoch 1/20\n",
      "60189/60189 [==============================] - 2s 37us/step - loss: 0.2581 - acc: 0.9258\n",
      "Epoch 2/20\n",
      "60189/60189 [==============================] - 2s 27us/step - loss: 0.1050 - acc: 0.9688\n",
      "Epoch 3/20\n",
      "60189/60189 [==============================] - 2s 27us/step - loss: 0.0692 - acc: 0.9791\n",
      "Epoch 4/20\n",
      "60189/60189 [==============================] - 2s 26us/step - loss: 0.0501 - acc: 0.9851\n",
      "Epoch 5/20\n",
      "60189/60189 [==============================] - 2s 28us/step - loss: 0.0374 - acc: 0.9888\n",
      "Epoch 6/20\n",
      "60189/60189 [==============================] - 2s 27us/step - loss: 0.0292 - acc: 0.9909\n",
      "Epoch 7/20\n",
      "60189/60189 [==============================] - 2s 29us/step - loss: 0.0227 - acc: 0.9934\n",
      "Epoch 8/20\n",
      "60189/60189 [==============================] - 2s 30us/step - loss: 0.0166 - acc: 0.9952\n",
      "Epoch 9/20\n",
      "60189/60189 [==============================] - 2s 31us/step - loss: 0.0139 - acc: 0.9961\n",
      "Epoch 10/20\n",
      "60189/60189 [==============================] - 2s 27us/step - loss: 0.0100 - acc: 0.9971\n",
      "Epoch 11/20\n",
      "60189/60189 [==============================] - 2s 28us/step - loss: 0.0078 - acc: 0.9978\n",
      "Epoch 12/20\n",
      "60189/60189 [==============================] - 2s 28us/step - loss: 0.0064 - acc: 0.9982\n",
      "Epoch 13/20\n",
      "60189/60189 [==============================] - 2s 28us/step - loss: 0.0052 - acc: 0.9987\n",
      "Epoch 14/20\n",
      "60189/60189 [==============================] - 2s 28us/step - loss: 0.0041 - acc: 0.9989\n",
      "Epoch 15/20\n",
      "60189/60189 [==============================] - 2s 29us/step - loss: 0.0031 - acc: 0.9992\n",
      "Epoch 16/20\n",
      "60189/60189 [==============================] - 2s 30us/step - loss: 0.0026 - acc: 0.9995\n",
      "Epoch 17/20\n",
      "60189/60189 [==============================] - 2s 30us/step - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 18/20\n",
      "60189/60189 [==============================] - 2s 29us/step - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 19/20\n",
      "60189/60189 [==============================] - 2s 28us/step - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 20/20\n",
      "60189/60189 [==============================] - 2s 31us/step - loss: 0.0012 - acc: 0.9997\n",
      "Evaluate on non-adversarial data\n",
      "Accuracy: 0.9823\n",
      "Evaluate the robustness\n",
      "0.994059405940594\n",
      "1 0.9782178217821782\n",
      "2 0.9613861381417453\n",
      "3 0.9287128708150127\n",
      "4 0.8841584154874972\n",
      "5 0.8207920795620078\n",
      "6 0.7940594058225651\n",
      "7 0.7841584157235552\n",
      "8 0.7831683167136542\n",
      "9 0.7831683167136542\n",
      "10 0.7831683167136542\n",
      "11 0.7831683167136542\n",
      "12 0.7831683167136542\n",
      "13 0.7831683167136542\n",
      "14 0.7831683167136542\n",
      "15 0.7831683167136542\n",
      "16 0.7831683167136542\n",
      "17 0.7831683167136542\n",
      "18 0.7831683167136542\n",
      "19 0.7831683167136542\n",
      "20 0.7831683167136542\n",
      "Iteration 1\n",
      "Generating adv examples for retraining\n",
      "1 0.998\n",
      "2 0.993\n",
      "3 0.959\n",
      "4 0.884\n",
      "5 0.832\n",
      "6 0.806\n",
      "7 0.801\n",
      "8 0.801\n",
      "9 0.801\n",
      "10 0.801\n",
      "11 0.801\n",
      "12 0.801\n",
      "13 0.801\n",
      "14 0.801\n",
      "15 0.801\n",
      "16 0.801\n",
      "17 0.801\n",
      "18 0.801\n",
      "19 0.801\n",
      "20 0.801\n",
      "Number of evasive samples to be added: (199,)\n",
      "Retrain the classifier\n",
      "Epoch 1/20\n",
      "60388/60388 [==============================] - 3s 43us/step - loss: 0.2592 - acc: 0.9255\n",
      "Epoch 2/20\n",
      "60388/60388 [==============================] - 2s 29us/step - loss: 0.1041 - acc: 0.9693\n",
      "Epoch 3/20\n",
      "60388/60388 [==============================] - 2s 30us/step - loss: 0.0700 - acc: 0.9793\n",
      "Epoch 4/20\n",
      "60388/60388 [==============================] - 2s 30us/step - loss: 0.0501 - acc: 0.9851\n",
      "Epoch 5/20\n",
      "60388/60388 [==============================] - 2s 29us/step - loss: 0.0383 - acc: 0.9885\n",
      "Epoch 6/20\n",
      "60388/60388 [==============================] - 2s 30us/step - loss: 0.0294 - acc: 0.9908\n",
      "Epoch 7/20\n",
      "60388/60388 [==============================] - 2s 31us/step - loss: 0.0221 - acc: 0.9938\n",
      "Epoch 8/20\n",
      "60388/60388 [==============================] - 2s 30us/step - loss: 0.0170 - acc: 0.9950\n",
      "Epoch 9/20\n",
      "60388/60388 [==============================] - 2s 29us/step - loss: 0.0132 - acc: 0.9960\n",
      "Epoch 10/20\n",
      "60388/60388 [==============================] - 2s 29us/step - loss: 0.0101 - acc: 0.9972\n",
      "Epoch 11/20\n",
      "60388/60388 [==============================] - 2s 30us/step - loss: 0.0081 - acc: 0.9978\n",
      "Epoch 12/20\n",
      "60388/60388 [==============================] - 2s 29us/step - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 13/20\n",
      "60388/60388 [==============================] - 2s 30us/step - loss: 0.0050 - acc: 0.9985\n",
      "Epoch 14/20\n",
      "60388/60388 [==============================] - 2s 29us/step - loss: 0.0039 - acc: 0.9991\n",
      "Epoch 15/20\n",
      "60388/60388 [==============================] - 2s 30us/step - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 16/20\n",
      "60388/60388 [==============================] - 2s 28us/step - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 17/20\n",
      "60388/60388 [==============================] - 2s 28us/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 18/20\n",
      "60388/60388 [==============================] - 2s 28us/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 19/20\n",
      "60388/60388 [==============================] - 2s 28us/step - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 20/20\n",
      "60388/60388 [==============================] - 2s 27us/step - loss: 0.0013 - acc: 0.9996\n",
      "Evaluate on non-adversarial data\n",
      "Accuracy: 0.9827\n",
      "Evaluate the robustness\n",
      "0.998019801980198\n",
      "1 0.9782178213100622\n",
      "2 0.9594059408301174\n",
      "3 0.9435643566717016\n",
      "4 0.9108910893449689\n",
      "5 0.8633663368697214\n",
      "6 0.8237623765917108\n",
      "7 0.7940594058225651\n",
      "8 0.7871287127532581\n",
      "9 0.7831683167136542\n",
      "10 0.7811881186938522\n",
      "11 0.7801980196839512\n",
      "12 0.7801980196839512\n",
      "13 0.7801980196839512\n",
      "14 0.7801980196839512\n",
      "15 0.7801980196839512\n",
      "16 0.7801980196839512\n",
      "17 0.7801980196839512\n",
      "18 0.7801980196839512\n",
      "19 0.7801980196839512\n",
      "20 0.7801980196839512\n",
      "Iteration 2\n",
      "Generating adv examples for retraining\n",
      "1 1.0\n",
      "2 0.996\n",
      "3 0.972\n",
      "4 0.932\n",
      "5 0.87\n",
      "6 0.822\n",
      "7 0.79\n",
      "8 0.778\n",
      "9 0.777\n",
      "10 0.776\n",
      "11 0.776\n",
      "12 0.776\n",
      "13 0.776\n",
      "14 0.776\n",
      "15 0.776\n",
      "16 0.776\n",
      "17 0.776\n",
      "18 0.776\n",
      "19 0.776\n",
      "20 0.776\n",
      "Number of evasive samples to be added: (224,)\n",
      "Retrain the classifier\n",
      "Epoch 1/20\n",
      "60612/60612 [==============================] - 2s 41us/step - loss: 0.2613 - acc: 0.9236\n",
      "Epoch 2/20\n",
      "60612/60612 [==============================] - 2s 26us/step - loss: 0.1057 - acc: 0.9682\n",
      "Epoch 3/20\n",
      "60612/60612 [==============================] - 2s 26us/step - loss: 0.0706 - acc: 0.9784\n",
      "Epoch 4/20\n",
      "60612/60612 [==============================] - 2s 27us/step - loss: 0.0516 - acc: 0.9846\n",
      "Epoch 5/20\n",
      "60612/60612 [==============================] - 2s 27us/step - loss: 0.0385 - acc: 0.9884\n",
      "Epoch 6/20\n",
      "60612/60612 [==============================] - 2s 25us/step - loss: 0.0297 - acc: 0.9908\n",
      "Epoch 7/20\n",
      "60612/60612 [==============================] - 2s 25us/step - loss: 0.0226 - acc: 0.9935\n",
      "Epoch 8/20\n",
      "60612/60612 [==============================] - 2s 26us/step - loss: 0.0173 - acc: 0.9947\n",
      "Epoch 9/20\n",
      "60612/60612 [==============================] - 2s 26us/step - loss: 0.0135 - acc: 0.9958\n",
      "Epoch 10/20\n",
      "60612/60612 [==============================] - 2s 26us/step - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 11/20\n",
      "60612/60612 [==============================] - 2s 26us/step - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 12/20\n",
      "60612/60612 [==============================] - 2s 27us/step - loss: 0.0062 - acc: 0.9984\n",
      "Epoch 13/20\n",
      "60612/60612 [==============================] - 2s 27us/step - loss: 0.0053 - acc: 0.9986\n",
      "Epoch 14/20\n",
      "60612/60612 [==============================] - 1s 24us/step - loss: 0.0039 - acc: 0.9990\n",
      "Epoch 15/20\n",
      "60612/60612 [==============================] - 1s 25us/step - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 16/20\n",
      "60612/60612 [==============================] - 2s 25us/step - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 17/20\n",
      "60612/60612 [==============================] - 2s 27us/step - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 18/20\n",
      "60612/60612 [==============================] - 2s 32us/step - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 19/20\n",
      "60612/60612 [==============================] - 2s 29us/step - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 20/20\n",
      "60612/60612 [==============================] - 2s 29us/step - loss: 0.0011 - acc: 0.9998\n",
      "Evaluate on non-adversarial data\n",
      "Accuracy: 0.9835\n",
      "Evaluate the robustness\n",
      "0.997029702970297\n",
      "1 0.9742574258606033\n",
      "2 0.9623762377417914\n",
      "3 0.9485148517212065\n",
      "4 0.9217821784538798\n",
      "5 0.8881188116451301\n",
      "6 0.8485148519572645\n",
      "7 0.8118811881188119\n",
      "8 0.7811881189299101\n",
      "9 0.7712871288309003\n",
      "10 0.7673267327912964\n",
      "11 0.7673267327912964\n",
      "12 0.7673267327912964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.7663366337813954\n",
      "14 0.7663366337813954\n",
      "15 0.7663366337813954\n",
      "16 0.7663366337813954\n",
      "17 0.7663366337813954\n",
      "18 0.7663366337813954\n",
      "19 0.7663366337813954\n",
      "20 0.7663366337813954\n"
     ]
    }
   ],
   "source": [
    "# Now let's retrain the classifier\n",
    "# First get the retraining seed and examples\n",
    "# We select 10% stratified from the training data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#X_def_seed, _, y_def_seed, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=0, stratify=y_train)\n",
    "#y_def_seed_encode = keras.utils.to_categorical(y_def_seed, num_classes)\n",
    "\n",
    "def_seed_ind = np.where(y_train == 3)[0][0:1000]\n",
    "X_def_seed = X_train[def_seed_ind]\n",
    "y_def_seed = y_train[def_seed_ind]\n",
    "y_def_seed_encode = y_train_encode[def_seed_ind]\n",
    "\n",
    "X_current_train = np.copy(X_train)\n",
    "y_current_train_encode = np.copy(y_train_encode)\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"Iteration {}\".format(i))\n",
    "    print(\"Generating adv examples for retraining\")\n",
    "    \n",
    "    if i == 0:\n",
    "        X_def_adv = adv_examples(model, X_def_seed, y_def_seed_encode, 0.01, 20)\n",
    "        y_def_adv_pred = model.predict(X_def_adv).argmax(axis=-1)\n",
    "    else:\n",
    "        X_def_adv = adv_examples(retrain_model, X_def_seed, y_def_seed_encode, 0.01, 20)\n",
    "        y_def_adv_pred = retrain_model.predict(X_def_adv).argmax(axis=-1)\n",
    "    def_evasive_ind = np.where(y_def_adv_pred != y_def_seed)[0]\n",
    "    X_def_evasive = X_def_adv[def_evasive_ind]\n",
    "    y_def_evasive = y_def_seed[def_evasive_ind]\n",
    "    y_def_evasive_encode = keras.utils.to_categorical(y_def_evasive, num_classes)\n",
    "    print(\"Number of evasive samples to be added: {}\".format(def_evasive_ind.shape))\n",
    "    \n",
    "    # Add the examples into the retraining data\n",
    "    print(\"Retrain the classifier\")\n",
    "    X_current_train = np.append(X_current_train, X_def_evasive, axis=0)\n",
    "    y_current_train_encode = np.append(y_current_train_encode, y_def_evasive_encode, axis=0)\n",
    "    \n",
    "    retrain_model = train(X_current_train, y_current_train_encode)\n",
    "\n",
    "    print(\"Evaluate on non-adversarial data\")\n",
    "    print(\"Accuracy: {}\".format(retrain_model.evaluate(X_test, y_test_encode, verbose=0)[1]))\n",
    "    \n",
    "    print(\"Evaluate the robustness\")\n",
    "    print(retrain_model.evaluate(X_adv, y_adv_seed_encode, verbose=0)[1])\n",
    "    X_adv = adv_examples(retrain_model, X_adv_seed, y_adv_seed_encode, 0.01, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173 594 826]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "y_adv_pred = retrain_model.predict(X_adv).argmax(axis=-1)\n",
    "adv_invasive_ind = np.where(y_adv_pred != y_adv_seed)[0] \n",
    "X_adv_evasive = X_adv[adv_invasive_ind]\n",
    "print(adv_invasive_ind[0:20])\n",
    "print(adv_invasive_ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = X_adv_seed[62].reshape(28,28)\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()\n",
    "img = X_adv[62].reshape(28,28)\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
